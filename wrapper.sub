#!/bin/bash
#SBATCH --job-name=parallel_infer
#SBATCH -p standard
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --array=0-10%200
#SBATCH --mem-per-cpu=6G
#SBATCH -A elread_lab

module load python/3.8.0
module load tensorflow
module load pytorch
batch=300
if [ $1 -eq 0 ];then
    python wrapper.py --counts $2 --index $(($SLURM_ARRAY_TASK_ID*$batch)) --end $batch --loop 1
elif [ $1 -eq 1 ];then
    python wrapper.py --pexp $2 --index $(($SLURM_ARRAY_TASK_ID*$batch)) --end $batch --loop 1 --downsample 0.3 --maxcount 275
elif [ $1 -eq 2 ];then
    python wrapper.py --psim $2 --index $(($SLURM_ARRAY_TASK_ID*$batch)) --end $batch --loop 1 --self 1 
fi
